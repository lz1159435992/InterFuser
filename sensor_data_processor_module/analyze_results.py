#!/usr/bin/env python3
"""
è¯„ä¼°ç»“æœåˆ†æè„šæœ¬

ç”¨äºåˆ†æå’Œæ¯”è¾ƒä¸åŒæ•°æ®å¤„ç†é…ç½®ä¸‹çš„è¯„ä¼°ç»“æœ
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, List, Any
import argparse
from datetime import datetime

def load_result(result_file: Path) -> Dict[str, Any]:
    """åŠ è½½è¯„ä¼°ç»“æœ JSON æ–‡ä»¶"""
    if not result_file.exists():
        raise FileNotFoundError(f"ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
    
    with open(result_file, 'r') as f:
        return json.load(f)

def load_metadata(eval_dir: Path) -> Dict[str, Any]:
    """åŠ è½½è¯„ä¼°å…ƒæ•°æ®"""
    metadata_file = eval_dir / "evaluation_metadata.json"
    if metadata_file.exists():
        with open(metadata_file, 'r') as f:
            return json.load(f)
    return {}

def calculate_statistics(result_data: Dict[str, Any]) -> Dict[str, Any]:
    """è®¡ç®—è¯„ä¼°ç»Ÿè®¡ä¿¡æ¯"""
    stats = {
        'total_routes': 0,
        'completed_routes': 0,
        'failed_routes': 0,
        'avg_driving_score': 0.0,
        'avg_route_completion': 0.0,
        'avg_infraction_penalty': 0.0,
        'total_infractions': 0,
        'infraction_breakdown': {},
    }
    
    if '_checkpoint' not in result_data:
        return stats
    
    checkpoint = result_data['_checkpoint']
    records = checkpoint.get('records', [])
    
    stats['total_routes'] = len(records)
    
    driving_scores = []
    route_completions = []
    infraction_penalties = []
    
    for record in records:
        status = record.get('status', 'Failed')
        scores = record.get('scores', {})
        
        if status == 'Completed':
            stats['completed_routes'] += 1
        else:
            stats['failed_routes'] += 1
        
        # æå–åˆ†æ•°
        driving_score = scores.get('score_route', 0.0)
        route_completion = scores.get('score_composed', 0.0)
        infraction_penalty = scores.get('score_penalty', 0.0)
        
        driving_scores.append(driving_score)
        route_completions.append(route_completion)
        infraction_penalties.append(infraction_penalty)
        
        # è¿è§„ç»Ÿè®¡
        infractions = record.get('infractions', {})
        for infraction_type, infraction_list in infractions.items():
            if infraction_type not in stats['infraction_breakdown']:
                stats['infraction_breakdown'][infraction_type] = 0
            stats['infraction_breakdown'][infraction_type] += len(infraction_list)
            stats['total_infractions'] += len(infraction_list)
    
    # è®¡ç®—å¹³å‡å€¼
    if driving_scores:
        stats['avg_driving_score'] = sum(driving_scores) / len(driving_scores)
    if route_completions:
        stats['avg_route_completion'] = sum(route_completions) / len(route_completions)
    if infraction_penalties:
        stats['avg_infraction_penalty'] = sum(infraction_penalties) / len(infraction_penalties)
    
    return stats

def print_single_result(result_file: Path, detailed: bool = False):
    """æ‰“å°å•ä¸ªç»“æœçš„åˆ†æ"""
    print("=" * 70)
    print(f"ğŸ“Š è¯„ä¼°ç»“æœåˆ†æ: {result_file.name}")
    print("=" * 70)
    print()
    
    # åŠ è½½æ•°æ®
    result_data = load_result(result_file)
    stats = calculate_statistics(result_data)
    
    # å°è¯•åŠ è½½å…ƒæ•°æ®
    eval_dir = result_file.parent.parent / "data" / "eval_with_processor" / result_file.stem
    metadata = load_metadata(eval_dir)
    
    if metadata:
        print("ğŸ”§ è¯„ä¼°é…ç½®:")
        print(f"  â€¢ æ—¶é—´æˆ³: {metadata.get('timestamp', 'N/A')}")
        print(f"  â€¢ è¯„ä¼°ç±»å‹: {metadata.get('eval_type', 'N/A')}")
        print(f"  â€¢ æ•°æ®å¤„ç†é…ç½®: {metadata.get('config_type', 'N/A')}")
        print(f"  â€¢ GPU ID: {metadata.get('gpu_id', 'N/A')}")
        print()
    
    print("ğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    print(f"  â€¢ æ€»è·¯çº¿æ•°: {stats['total_routes']}")
    print(f"  â€¢ å®Œæˆè·¯çº¿æ•°: {stats['completed_routes']}")
    print(f"  â€¢ å¤±è´¥è·¯çº¿æ•°: {stats['failed_routes']}")
    print(f"  â€¢ å®Œæˆç‡: {stats['completed_routes']/stats['total_routes']*100:.2f}%" if stats['total_routes'] > 0 else "  â€¢ å®Œæˆç‡: N/A")
    print()
    
    print("ğŸ¯ æ€§èƒ½æŒ‡æ ‡:")
    print(f"  â€¢ å¹³å‡é©¾é©¶åˆ†æ•°: {stats['avg_driving_score']:.2f}")
    print(f"  â€¢ å¹³å‡è·¯çº¿å®Œæˆåº¦: {stats['avg_route_completion']:.2f}")
    print(f"  â€¢ å¹³å‡è¿è§„æƒ©ç½š: {stats['avg_infraction_penalty']:.2f}")
    print()
    
    print("âš ï¸  è¿è§„ç»Ÿè®¡:")
    print(f"  â€¢ æ€»è¿è§„æ¬¡æ•°: {stats['total_infractions']}")
    if stats['infraction_breakdown']:
        print("  â€¢ è¿è§„è¯¦æƒ…:")
        for infraction_type, count in sorted(stats['infraction_breakdown'].items(), key=lambda x: x[1], reverse=True):
            print(f"    - {infraction_type}: {count} æ¬¡")
    else:
        print("  â€¢ æ— è¿è§„è®°å½•")
    print()
    
    if detailed and '_checkpoint' in result_data:
        print("ğŸ“‹ è¯¦ç»†è·¯çº¿ç»“æœ:")
        print("-" * 70)
        records = result_data['_checkpoint'].get('records', [])
        for i, record in enumerate(records, 1):
            route_id = record.get('route_id', f'Route {i}')
            status = record.get('status', 'Unknown')
            scores = record.get('scores', {})
            
            print(f"\n  è·¯çº¿ {route_id}:")
            print(f"    çŠ¶æ€: {status}")
            print(f"    é©¾é©¶åˆ†æ•°: {scores.get('score_route', 0.0):.2f}")
            print(f"    å®Œæˆåº¦: {scores.get('score_composed', 0.0):.2f}")
            print(f"    è¿è§„æƒ©ç½š: {scores.get('score_penalty', 0.0):.2f}")
            
            infractions = record.get('infractions', {})
            total_route_infractions = sum(len(v) for v in infractions.values())
            if total_route_infractions > 0:
                print(f"    è¿è§„æ¬¡æ•°: {total_route_infractions}")
        print()

def compare_results(result_files: List[Path]):
    """æ¯”è¾ƒå¤šä¸ªç»“æœ"""
    print("=" * 70)
    print("ğŸ“Š è¯„ä¼°ç»“æœå¯¹æ¯”")
    print("=" * 70)
    print()
    
    results = []
    for result_file in result_files:
        try:
            result_data = load_result(result_file)
            stats = calculate_statistics(result_data)
            
            # å°è¯•åŠ è½½å…ƒæ•°æ®
            eval_dir = result_file.parent.parent / "data" / "eval_with_processor" / result_file.stem
            metadata = load_metadata(eval_dir)
            
            results.append({
                'file': result_file,
                'stats': stats,
                'metadata': metadata
            })
        except Exception as e:
            print(f"âš ï¸  è·³è¿‡ {result_file.name}: {e}")
    
    if not results:
        print("æ²¡æœ‰æœ‰æ•ˆçš„ç»“æœå¯ä¾›æ¯”è¾ƒ")
        return
    
    # æ‰“å°å¯¹æ¯”è¡¨æ ¼
    print(f"{'é…ç½®ç±»å‹':<15} {'å®Œæˆç‡':<10} {'é©¾é©¶åˆ†æ•°':<12} {'å®Œæˆåº¦':<12} {'è¿è§„æ¬¡æ•°':<10}")
    print("-" * 70)
    
    for result in results:
        config_type = result['metadata'].get('config_type', 'Unknown')
        stats = result['stats']
        
        completion_rate = f"{stats['completed_routes']/stats['total_routes']*100:.1f}%" if stats['total_routes'] > 0 else "N/A"
        
        print(f"{config_type:<15} {completion_rate:<10} {stats['avg_driving_score']:<12.2f} "
              f"{stats['avg_route_completion']:<12.2f} {stats['total_infractions']:<10}")
    
    print()
    
    # æ€§èƒ½å¯¹æ¯”åˆ†æ
    print("ğŸ” æ€§èƒ½å¯¹æ¯”åˆ†æ:")
    print()
    
    if len(results) >= 2:
        # æ‰¾åˆ°åŸºå‡†ï¼ˆé€šå¸¸æ˜¯æ— å¤„ç†æˆ–è½»åº¦å¤„ç†ï¼‰
        baseline = None
        for result in results:
            config_type = result['metadata'].get('config_type', '')
            if config_type in ['mild', 'baseline', 'no_processing']:
                baseline = result
                break
        
        if not baseline:
            baseline = results[0]
        
        baseline_name = baseline['metadata'].get('config_type', 'baseline')
        print(f"  åŸºå‡†é…ç½®: {baseline_name}")
        print()
        
        for result in results:
            if result == baseline:
                continue
            
            config_type = result['metadata'].get('config_type', 'Unknown')
            
            # è®¡ç®—ç›¸å¯¹å˜åŒ–
            driving_score_diff = result['stats']['avg_driving_score'] - baseline['stats']['avg_driving_score']
            completion_diff = result['stats']['avg_route_completion'] - baseline['stats']['avg_route_completion']
            infraction_diff = result['stats']['total_infractions'] - baseline['stats']['total_infractions']
            
            print(f"  {config_type} vs {baseline_name}:")
            print(f"    é©¾é©¶åˆ†æ•°å˜åŒ–: {driving_score_diff:+.2f}")
            print(f"    å®Œæˆåº¦å˜åŒ–: {completion_diff:+.2f}")
            print(f"    è¿è§„æ¬¡æ•°å˜åŒ–: {infraction_diff:+d}")
            print()

def main():
    parser = argparse.ArgumentParser(
        description='åˆ†æ InterFuser è¯„ä¼°ç»“æœ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  # åˆ†æå•ä¸ªç»“æœ
  %(prog)s results/with_processor/town05_moderate_20250101_120000.json
  
  # è¯¦ç»†åˆ†æ
  %(prog)s -d results/with_processor/town05_moderate_20250101_120000.json
  
  # å¯¹æ¯”å¤šä¸ªç»“æœ
  %(prog)s -c results/with_processor/town05_mild_*.json results/with_processor/town05_moderate_*.json
  
  # åˆ†æç›®å½•ä¸­çš„æ‰€æœ‰ç»“æœ
  %(prog)s -c results/with_processor/*.json
        '''
    )
    
    parser.add_argument('files', nargs='+', type=Path, help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒé€šé…ç¬¦ï¼‰')
    parser.add_argument('-d', '--detailed', action='store_true', help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆæ¯æ¡è·¯çº¿ï¼‰')
    parser.add_argument('-c', '--compare', action='store_true', help='å¯¹æ¯”æ¨¡å¼ï¼ˆæ¯”è¾ƒå¤šä¸ªç»“æœï¼‰')
    
    args = parser.parse_args()
    
    # å±•å¼€é€šé…ç¬¦
    result_files = []
    for pattern in args.files:
        if pattern.exists() and pattern.is_file():
            result_files.append(pattern)
        else:
            # å°è¯•ä½œä¸ºé€šé…ç¬¦åŒ¹é…
            parent = pattern.parent
            if parent.exists():
                result_files.extend(parent.glob(pattern.name))
    
    result_files = sorted(set(result_files))  # å»é‡å¹¶æ’åº
    
    if not result_files:
        print("é”™è¯¯: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶")
        sys.exit(1)
    
    if args.compare or len(result_files) > 1:
        compare_results(result_files)
    else:
        print_single_result(result_files[0], detailed=args.detailed)

if __name__ == '__main__':
    main()

